{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized String Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strength of Python is its relative ease in handling and manipulating string data.\n",
    "Pandas builds on this and provides a comprehensive set of *vectorized string operations* that are an important part of the type of munging required when working with (read: cleaning up) real-world data.\n",
    "In this chapter, we'll walk through some of the Pandas string operations, and then take a look at using them to partially clean up a very messy dataset of recipes collected from the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Pandas String Operations\n",
    "\n",
    "We saw in previous chapters how tools like NumPy and Pandas generalize arithmetic operations so that we can easily and quickly perform the same operation on many array elements. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6, 10, 14, 18, 22, 26, 30])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 3, 5, 7, 9, 11, 13, 15])\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This *vectorization* of operations simplifies the syntax of operating on arrays of data: we no longer have to worry about the size or shape of the array, but just about what operation we want done.\n",
    "For arrays of strings, NumPy does not provide such simple access, and thus you're stuck using a more verbose loop syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peter', 'Paul', 'Mary', 'Guido']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is perhaps sufficient to work with some data, but it will break if there are any missing values, so this approach requires putting in extra checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peter', 'Paul', None, 'Mary', 'Guido']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "[s if s is None else s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of manual approach is not only verbose and inconvenient, it can be error-prone.\n",
    "\n",
    "Pandas includes features to address both this need for vectorized string operations and the need for correctly handling missing data via the `str` attribute of Pandas `Series` and `Index` objects containing strings.\n",
    "So, for example, if we create a Pandas `Series` with this data we can directly call the `str.capitalize` method, which has missing value handling built in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Peter\n",
       "1     Paul\n",
       "2     None\n",
       "3     Mary\n",
       "4    Guido\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "names = pd.Series(data)\n",
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables of Pandas String Methods\n",
    "\n",
    "If you have a good understanding of string manipulation in Python, most of the Pandas string syntax is intuitive enough that it's probably sufficient to just list the available methods. We'll start with that here, before diving deeper into a few of the subtleties.\n",
    "The examples in this section use the following `Series` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "monte = pd.Series(['Graham Chapman', 'John Cleese', 'Terry Gilliam',\n",
    "                   'Eric Idle', 'Terry Jones', 'Michael Palin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods Similar to Python String Methods\n",
    "\n",
    "Nearly all of Python's built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas `str` methods that mirror Python string methods:\n",
    "\n",
    "|           |                |                |                |\n",
    "|-----------|----------------|----------------|----------------|\n",
    "|`len()`    | `lower()`      | `translate()`  | `islower()`    | \n",
    "|`ljust()`  | `upper()`      | `startswith()` | `isupper()`    | \n",
    "|`rjust()`  | `find()`       | `endswith()`   | `isnumeric()`  | \n",
    "|`center()` | `rfind()`      | `isalnum()`    | `isdecimal()`  | \n",
    "|`zfill()`  | `index()`      | `isalpha()`    | `split()`      | \n",
    "|`strip()`  | `rindex()`     | `isdigit()`    | `rsplit()`     | \n",
    "|`rstrip()` | `capitalize()` | `isspace()`    | `partition()`  | \n",
    "|`lstrip()` | `swapcase()`   | `istitle()`    | `rpartition()` |\n",
    "\n",
    "Notice that these have various return values. Some, like `lower`, return a series of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    graham chapman\n",
       "1       john cleese\n",
       "2     terry gilliam\n",
       "3         eric idle\n",
       "4       terry jones\n",
       "5     michael palin\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But some others return numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "1    11\n",
       "2    13\n",
       "3     9\n",
       "4    11\n",
       "5    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or Boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.startswith('T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still others return lists or other compound values for each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Graham, Chapman]\n",
       "1       [John, Cleese]\n",
       "2     [Terry, Gilliam]\n",
       "3         [Eric, Idle]\n",
       "4       [Terry, Jones]\n",
       "5     [Michael, Palin]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see further manipulations of this kind of series-of-lists object as we continue our discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods Using Regular Expressions\n",
    "\n",
    "In addition, there are several methods that accept regular expressions (regexps) to examine the content of each string element, and follow some of the API conventions of Python's built-in `re` module:\n",
    "\n",
    "| Method    | Description |\n",
    "|-----------|-------------|\n",
    "| `match`   | Calls `re.match` on each element, returning a Boolean. |\n",
    "| `extract` | Calls `re.match` on each element, returning matched groups as strings.|\n",
    "| `findall` | Calls `re.findall` on each element |\n",
    "| `replace` | Replaces occurrences of pattern with some other string|\n",
    "| `contains`| Calls `re.search` on each element, returning a boolean |\n",
    "| `count`   | Counts occurrences of pattern|\n",
    "| `split`   | Equivalent to `str.split`, but accepts regexps |\n",
    "| `rsplit`  | Equivalent to `str.rsplit`, but accepts regexps |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, we can do a wide range of operations.\n",
    "For example, we can extract the first name from each element by asking for a contiguous group of characters at the beginning of each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Graham\n",
       "1       John\n",
       "2      Terry\n",
       "3       Eric\n",
       "4      Terry\n",
       "5    Michael\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.extract('([A-Za-z]+)', expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do something more complicated, like finding all names that start and end with a consonant, making use of the start-of-string (`^`) and end-of-string (`$`) regular expression characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Graham Chapman]\n",
       "1                  []\n",
       "2     [Terry Gilliam]\n",
       "3                  []\n",
       "4       [Terry Jones]\n",
       "5     [Michael Palin]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.findall(r'^[^AEIOU].*[^aeiou]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to concisely apply regular expressions across `Series` or `DataFrame` entries opens up many possibilities for analysis and cleaning of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous Methods\n",
    "Finally, there are some miscellaneous methods that enable other convenient operations:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `get` | Indexes each element |\n",
    "| `slice` | Slices each element|\n",
    "| `slice_replace` | Replaces slice in each element with the passed value|\n",
    "| `cat`      | Concatenates strings|\n",
    "| `repeat` | Repeats values |\n",
    "| `normalize` | Returns Unicode form of strings |\n",
    "| `pad` | Adds whitespace to left, right, or both sides of strings|\n",
    "| `wrap` | Splits long strings into lines with length less than a given width|\n",
    "| `join` | Joins strings in each element of the `Series` with the passed separator|\n",
    "| `get_dummies` | Extracts dummy variables as a `DataFrame` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized item access and slicing\n",
    "\n",
    "The `get` and `slice` operations, in particular, enable vectorized element access from each array.\n",
    "For example, we can get a slice of the first three characters of each array using `str.slice(0, 3)`.\n",
    "Note that this behavior is also available through Python's normal indexing syntax; for example, `df.str.slice(0, 3)` is equivalent to `df.str[0:3]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Gra\n",
       "1    Joh\n",
       "2    Ter\n",
       "3    Eri\n",
       "4    Ter\n",
       "5    Mic\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing via `df.str.get(i)` and `df.str[i]` are likewise similar.\n",
    "\n",
    "These indexing methods also let you access elements of arrays returned by `split`.\n",
    "For example, to extract the last name of each entry, we can combine `split` with `str` indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Chapman\n",
       "1     Cleese\n",
       "2    Gilliam\n",
       "3       Idle\n",
       "4      Jones\n",
       "5      Palin\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte.str.split().str[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicator variables\n",
    "\n",
    "Another method that requires a bit of extra explanation is the `get_dummies` method.\n",
    "This is useful when your data has a column containing some sort of coded indicator.\n",
    "For example, we might have a dataset that contains information in the form of codes, such as A = \"born in America,\" B = \"born in the United Kingdom,\" C = \"likes cheese,\" D = \"likes spam\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graham Chapman</td>\n",
       "      <td>B|C|D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Cleese</td>\n",
       "      <td>B|D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terry Gilliam</td>\n",
       "      <td>A|C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Idle</td>\n",
       "      <td>B|D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terry Jones</td>\n",
       "      <td>B|C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael Palin</td>\n",
       "      <td>B|C|D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name   info\n",
       "0  Graham Chapman  B|C|D\n",
       "1     John Cleese    B|D\n",
       "2   Terry Gilliam    A|C\n",
       "3       Eric Idle    B|D\n",
       "4     Terry Jones    B|C\n",
       "5   Michael Palin  B|C|D"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_monte = pd.DataFrame({'name': monte,\n",
    "                           'info': ['B|C|D', 'B|D', 'A|C',\n",
    "                                    'B|D', 'B|C', 'B|C|D']})\n",
    "full_monte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_dummies` routine lets us split out these indicator variables into a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  0  1  1  1\n",
       "1  0  1  0  1\n",
       "2  1  0  1  0\n",
       "3  0  1  0  1\n",
       "4  0  1  1  0\n",
       "5  0  1  1  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_monte['info'].str.get_dummies('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these operations as building blocks, you can construct an endless range of string processing procedures when cleaning your data.\n",
    "\n",
    "We won't dive further into these methods here, but I encourage you to read through [\"Working with Text Data\"](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html) in the Pandas online documentation, or to refer to the resources listed in [Further Resources](03.13-Further-Resources.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Recipe Database\n",
    "\n",
    "These vectorized string operations become most useful in the process of cleaning up messy, real-world data.\n",
    "Here I'll walk through an example of that, using an open recipe database compiled from various sources on the web.\n",
    "Our goal will be to parse the recipe data into ingredient lists, so we can quickly find a recipe based on some ingredients we have on hand. The scripts used to compile this can be found at https://github.com/fictivekin/openrecipes, and the link to the most recent version of the database is found there as well.\n",
    "\n",
    "This database is about 30 MB, and can be downloaded and unzipped with these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# repo = \"https://raw.githubusercontent.com/jakevdp/open-recipe-data/master\"\n",
    "# !cd data && curl -O {repo}/recipeitems.json.gz\n",
    "# !gunzip data/recipeitems.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is in JSON format, so we will use `pd.read_json` to read it (`lines=True` is required for this dataset because each line of the file is a JSON entry):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_json('data/recipeitems.json', lines=True)\n",
    "recipes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are nearly 175,000 recipes, and 17 columns.\n",
    "Let's take a look at one row to see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                             Ginger Stew\n",
       "ingredients    [butter, olive oil, peas, tomato, corn, rice]\n",
       "minutes                                                   99\n",
       "calories                                                 449\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information there, but much of it is in a very messy form, as is typical of data scraped from the web.\n",
    "In particular, the ingredient list is in string format; we're going to have to carefully extract the information we're interested in.\n",
    "Let's start by taking a closer look at the ingredients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150.000000\n",
       "mean       4.526667\n",
       "std        1.084959\n",
       "min        3.000000\n",
       "25%        4.000000\n",
       "50%        5.000000\n",
       "75%        5.000000\n",
       "max        6.000000\n",
       "Name: ingredients, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.ingredients.str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ingredient lists average 250 characters long, with a minimum of 0 and a maximum of nearly 10,000 characters!\n",
    "\n",
    "Just out of curiosity, let's see which recipe has the longest ingredient list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ginger Stew'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.name[np.argmax(recipes.ingredients.str.len())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do other aggregate explorations; for example, we can see how many of the recipes are for breakfast foods (using regular expression syntax to match both lowercase and capital letters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13260\\436987916.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m recipes.description.str.contains(\u001b[33m'[Bb]reakfast'\u001b[39m).sum()\n",
      "\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'description'"
     ]
    }
   ],
   "source": [
    "recipes.description.str.contains('[Bb]reakfast').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or how many of the recipes list cinnamon as an ingredient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.ingredients.str.contains('[Cc]innamon').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could even look to see whether any recipes misspell the ingredient as \"cinamon\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.ingredients.str.contains('[Cc]inamon').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the type of data exploration that is possible with Pandas string tools.\n",
    "It is data munging like this that Python really excels at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Recipe Recommender\n",
    "\n",
    "Let's go a bit further, and start working on a simple recipe recommendation system: given a list of ingredients, we want to find any recipes that use all those ingredients.\n",
    "While conceptually straightforward, the task is complicated by the heterogeneity of the data: there is no easy operation, for example, to extract a clean list of ingredients from each row.\n",
    "So, we will cheat a bit: we'll start with a list of common ingredients, and simply search to see whether they are in each recipe's ingredient list.\n",
    "For simplicity, let's just stick with herbs and spices for the time being:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spice_list = ['salt', 'pepper', 'oregano', 'sage', 'parsley',\n",
    "              'rosemary', 'tarragon', 'thyme', 'paprika', 'cumin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then build a Boolean `DataFrame` consisting of `True` and `False` values, indicating whether each ingredient appears in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salt</th>\n",
       "      <th>pepper</th>\n",
       "      <th>oregano</th>\n",
       "      <th>sage</th>\n",
       "      <th>parsley</th>\n",
       "      <th>rosemary</th>\n",
       "      <th>tarragon</th>\n",
       "      <th>thyme</th>\n",
       "      <th>paprika</th>\n",
       "      <th>cumin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salt  pepper  oregano  sage  parsley  rosemary  tarragon  thyme  paprika  \\\n",
       "0   NaN     NaN      NaN   NaN      NaN       NaN       NaN    NaN      NaN   \n",
       "1   NaN     NaN      NaN   NaN      NaN       NaN       NaN    NaN      NaN   \n",
       "2   NaN     NaN      NaN   NaN      NaN       NaN       NaN    NaN      NaN   \n",
       "3   NaN     NaN      NaN   NaN      NaN       NaN       NaN    NaN      NaN   \n",
       "4   NaN     NaN      NaN   NaN      NaN       NaN       NaN    NaN      NaN   \n",
       "\n",
       "   cumin  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "spice_df = pd.DataFrame({\n",
    "    spice: recipes.ingredients.str.contains(spice, re.IGNORECASE)\n",
    "    for spice in spice_list})\n",
    "spice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as an example, let's say we'd like to find a recipe that uses parsley, paprika, and tarragon.\n",
    "We can compute this very quickly using the `query` method of ``DataFrame``s, discussed further in [High-Performance Pandas: `eval()` and `query()`](03.12-Performance-Eval-and-Query.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "couldn't find matching opcode for 'and_bbd'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\numexpr\\necompiler.py:892\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(ex, local_dict, global_dict, out, order, casting, _frame_depth, sanitize, **kwargs)\u001b[39m\n\u001b[32m    891\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     compiled_ex = _numexpr_cache.c[numexpr_key]\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: ('((parsley) & (paprika)) & (tarragon)', (('optimization', 'aggressive'), ('truediv', False)), (('paprika', <class 'numpy.float64'>), ('parsley', <class 'numpy.float64'>), ('tarragon', <class 'numpy.float64'>)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m selection = spice_df.query(\u001b[33m'\u001b[39m\u001b[33mparsley & paprika & tarragon\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mlen\u001b[39m(selection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\frame.py:4828\u001b[39m, in \u001b[36mDataFrame.query\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4826\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m   4827\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4828\u001b[39m res = \u001b[38;5;28mself\u001b[39m.eval(expr, **kwargs)\n\u001b[32m   4830\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4831\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.loc[res]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[39m, in \u001b[36mDataFrame.eval\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4951\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   4952\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mtuple\u001b[39m(kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m, ())) + resolvers\n\u001b[32m-> \u001b[39m\u001b[32m4954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _eval(expr, inplace=inplace, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\computation\\eval.py:363\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[39m\n\u001b[32m    361\u001b[39m eng = ENGINES[engine]\n\u001b[32m    362\u001b[39m eng_inst = eng(parsed_expr)\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m ret = eng_inst.evaluate()\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parsed_expr.assigner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m multi_line:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\computation\\engines.py:81\u001b[39m, in \u001b[36mAbstractEngine.evaluate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.result_type, \u001b[38;5;28mself\u001b[39m.aligned_axes = align_terms(\u001b[38;5;28mself\u001b[39m.expr.terms)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# make sure no names in resolvers and locals/globals clash\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m res = \u001b[38;5;28mself\u001b[39m._evaluate()\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reconstruct_object(\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.result_type, res, \u001b[38;5;28mself\u001b[39m.aligned_axes, \u001b[38;5;28mself\u001b[39m.expr.terms.return_type\n\u001b[32m     84\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\pandas\\core\\computation\\engines.py:121\u001b[39m, in \u001b[36mNumExprEngine._evaluate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    119\u001b[39m scope = env.full_scope\n\u001b[32m    120\u001b[39m _check_ne_builtin_clash(\u001b[38;5;28mself\u001b[39m.expr)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ne.evaluate(s, local_dict=scope)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\numexpr\\necompiler.py:978\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(ex, local_dict, global_dict, out, order, casting, sanitize, _frame_depth, **kwargs)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m re_evaluate(local_dict=local_dict, global_dict=global_dict, _frame_depth=_frame_depth)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\numexpr\\necompiler.py:894\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(ex, local_dict, global_dict, out, order, casting, _frame_depth, sanitize, **kwargs)\u001b[39m\n\u001b[32m    892\u001b[39m     compiled_ex = _numexpr_cache.c[numexpr_key]\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     compiled_ex = _numexpr_cache.c[numexpr_key] = NumExpr(ex, signature, sanitize=sanitize, **context)\n\u001b[32m    895\u001b[39m kwargs = {\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m: out, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m: order, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m: casting,\n\u001b[32m    896\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mex_uses_vml\u001b[39m\u001b[33m'\u001b[39m: ex_uses_vml}\n\u001b[32m    897\u001b[39m _numexpr_last.l.set(ex=compiled_ex, argnames=names, kwargs=kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\numexpr\\necompiler.py:642\u001b[39m, in \u001b[36mNumExpr\u001b[39m\u001b[34m(ex, signature, sanitize, **kwargs)\u001b[39m\n\u001b[32m    640\u001b[39m _frame_depth = \u001b[32m1\u001b[39m\n\u001b[32m    641\u001b[39m context = getContext(kwargs, _frame_depth=_frame_depth)\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m threeAddrProgram, inputsig, tempsig, constants, input_names = precompile(ex, signature, context, sanitize=sanitize)\n\u001b[32m    643\u001b[39m program = compileThreeAddrForm(threeAddrProgram)\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m interpreter.NumExpr(inputsig.encode(\u001b[33m'\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    645\u001b[39m                            tempsig.encode(\u001b[33m'\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    646\u001b[39m                            program, constants, input_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\numexpr\\necompiler.py:589\u001b[39m, in \u001b[36mprecompile\u001b[39m\u001b[34m(ex, signature, context, sanitize)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ex.astType != \u001b[33m'\u001b[39m\u001b[33mop\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    587\u001b[39m     ast = ASTNode(\u001b[33m'\u001b[39m\u001b[33mop\u001b[39m\u001b[33m'\u001b[39m, value=\u001b[33m'\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m'\u001b[39m, astKind=ex.astKind, children=(ast,))\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m ast = typeCompileAst(ast)\n\u001b[32m    591\u001b[39m aliases = collapseDuplicateSubtrees(ast)\n\u001b[32m    593\u001b[39m assignLeafRegisters(ast.allOf(\u001b[33m'\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m'\u001b[39m), Immediate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicek\\anaconda3\\envs\\anaconda-toolbox\\Lib\\site-packages\\numexpr\\necompiler.py:206\u001b[39m, in \u001b[36mtypeCompileAst\u001b[39m\u001b[34m(ast)\u001b[39m\n\u001b[32m    204\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    207\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find matching opcode for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m             % (ast.value + \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m + retsig + basesig))\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# First just cast constants, then cast variables if necessary:\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (have, want) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(basesig, sig)):\n",
      "\u001b[31mNotImplementedError\u001b[39m: couldn't find matching opcode for 'and_bbd'"
     ]
    }
   ],
   "source": [
    "selection = spice_df.query('parsley & paprika & tarragon')\n",
    "len(selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find only 10 recipes with this combination. Let's use the index returned by this selection to discover the names of those recipes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m recipes.name[selection.index]\n",
      "\u001b[31mNameError\u001b[39m: name 'selection' is not defined"
     ]
    }
   ],
   "source": [
    "recipes.name[selection.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have narrowed down our recipe selection from 175,000 to 10, we are in a position to make a more informed decision about what we'd like to cook for dinner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Further with Recipes\n",
    "\n",
    "Hopefully this example has given you a bit of a flavor (heh) of the types of data cleaning operations that are efficiently enabled by Pandas string methods.\n",
    "Of course, building a robust recipe recommendation system would require a *lot* more work!\n",
    "Extracting full ingredient lists from each recipe would be an important piece of the task; unfortunately, the wide variety of formats used makes this a relatively time-consuming process.\n",
    "This points to the truism that in data science, cleaning and munging of real-world data often comprises the majority of the workâ€”and Pandas provides the tools that can help you do this efficiently."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "anaconda-toolbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
